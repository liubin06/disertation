%%% mode: latex
%%% TeX-master: t
%%% End:

\chapter{基础理论与相关工作}
\label{cha:intro1}
%对比学习是自监督学习的重要途径，在计算机视觉、自然语言处理等诸多领域取得了瞩目的成就，推荐算法也根植于这一范式。正样本增强、负样本采样、损失函数设计，是对比学习的核心组件，也是提升推荐性能的关键途径。本章首先介绍对比学习的基本概念，并分析了推荐中的主流方法成对学习与对比学习的联系。然后介绍对比的研究现状，包括正样本的数据增强、负样本采样、网络架构设计以及损失函数设计。最后，介绍本文会使用到的一些重要的预备知识。

不完全标注的隐式反馈数据是制约推荐模型充分发挥潜力的瓶颈。自监督学习（SSL）[9]作为一种学习范式，可以减少对手动标签的依赖，并能够在海量无标签数据上进行训练。推荐系统中最先进的模型也借鉴了自监督学习的技术，使得从稀疏的隐式反馈数据集上训练推荐系统称为可能。本章首先从自监督学习的角度对推荐系统的现有工作进行梳理。其次对自监督学习的主要途径--对比学习基础理论与相关工作进行介绍。最后，介绍本文会使用到的一些重要的预备知识。

\section{自监督推荐算法（SSR）相关工作}
近年来，借助深度神经网络模型的强大拟合能力和泛化性能，推荐系统取得了巨大的成功。然而，基于深度神经网络模型的推荐模型需要大量的训练数据。与可以通过众包完成的图像注释任务不同，推荐系统中的数据获取成本很高，因为个性化推荐依赖用户自身生成的数据，需要准确标注用户对海量物品的喜欢/不喜欢程度，才能使得推荐模型准确捕捉用户的偏好，从而产生准确的推荐。不幸的是，大多数用户通常只与众多物品中的一小部分进行交互[7]。因此，隐式反馈数据的稀疏性和标注不完全性问题成为制约深度推荐模型充分发挥潜力的瓶颈[8]。

自监督学习（SSL）[9]作为一种学习范式，充分利用输入数据中的内在关系，通过对输入数据进行某种变换或处理来创建“伪标签”，可以减少对手动标签的依赖，最近受到了相当大的关注。SSL的基本思想是通过精心设计的自监督任务（即预训练任务），从丰富的无标签数据中提取可迁移的知识，其中监督信号是半自动生成的。由于能够克服广泛存在的标签不足问题，SSL已经应用于包括视觉表示学习[10]，[11]，[12]，语言模型预训练[13]，[14]，音频表示学习[15]，节点/图分类[16]，[17]等各个领域。特别是对比学习（CL）的复兴[28]显着推动了SSL的前沿。最新的基于自监督学习的方法甚至在许多计算机视觉（CV）和自然语言处理（NLP）任务中表现出与有监督模型相当的性能[11]，[27]。由于自监督学习的原则与推荐系统对更多注释数据的需求相吻合，受到自监督学习在其他领域取得的巨大成功的启发，目前已经有大量不断增长的研究探索将SSL应用于推荐领域。

自监督推荐（Self-Supervised  Recommendation,  SSR）模型为克服推荐系统中的数据稀疏问题提供了一种新的途径。综合文献\cite{Liu:2021:TKDE}和文献【ref】的归纳，总结了自监督推荐（SSR）的三个关键特征如下：
\begin{itemize}
\item 半自动地利用原始数据本身进行标注。自监督推荐充分利用输入数据中的内在关系，通过对输入数据进行某种变换或处理来创建“伪标签”。例如BPR\cite{Steffen:2009:UAI}将交互的物品自动标记为正例，而未交互的物品标记为负例，就是在执行自动化标注过程。需要注意的是，这个标签是伪标签，不同于用户喜欢与否的真实偏好标签。

\item 通过提取自监督信号对推荐模型进行（预）训练的任务。常见的自监督信号如BPR中“用户对正例的偏好强于负例”，常用用于优化成对损失。另一种常见的自监督信号是用户物品二分图的图数据增强和原图的语义不变性，常用于优化对比损失优化目标。

\item 自监督任务旨在提升推荐性能，而非作为最终目标。这一特征强调了推荐任务和自监督任务之间的主辅关系，学习良好的用户物品特征表示，是为了产生更准确的个性化推荐结果。
\end{itemize}

根据其自监督任务的性质，可以将现有的自监督推荐模型分为四个类别：对比型、预测型、生成型和混合型。下文对自监督模型的类别进行介绍。
\subsection{对比型推荐算法}
根据自监督信号的来源，对比型的推荐算法可以分为三种类型：结构层对比、特征层对比和模型层对比。
\subsubsection{结构层对比}
结构层对比的自监督信号主要来自于图结构扰动的语义不变性，核心思想是：对图数据（Graph）进行轻微扰动,可能会导致类似的语义。通过对比不同的图数据，可以获得对结构扰动的共享不变性作为自监督信号。本文遵循文献[35]，[36]提出的分类法，将结构层对比分为两类：同尺度对比和跨尺度对比。同尺度对比涉及同一尺度上两个对象的视图，并进一步分为两个级别：局部-局部对比（Local-Local Contrast），全局-全局对比（Global-Global Contrast）。跨尺度对比涉及来自不同尺度上两个对象的视图，并进一步分为局部-全局对比（Local-Global Contrast）和局部-上下文对比（Local-Context Contrast）。

对于\textbf{局部-局部对比}（Local-Local Contrast），基于dropout的增强方法是创建扰动局部视图的最常用方法。作为代表性模型，SGL [31] 将节点dropout、边dropout和随机游走增强应用于用户-物品二分图。它使用相同类型的增强操作生成两个增强图，并使用共享的图LightGCN[84]编码器学习节点嵌入。节点级对比使用InfoNCE损失 [15] 进行优化，采用批内负采样，并与推荐的贝叶斯个性化排名（BPR）损失 [85] 进行联合优化。类似地，DCL [86] 使用随机边dropout来扰动节点的L-hop邻居网络，生成两个增强的邻域子图。然后，它最大化在这两个子图上学习到的节点表示之间的一致性。HHGR [62] 提出了一种双尺度节点dropout方法，用于群组推荐 [87]。该方法包括粗粒度和细粒度的dropout方案，分别从所有群组中删除一部分用户节点，以及仅从特定群组中随机选择成员节点。然后，它最大化从这两个具有不同dropout粒度的视图学习到的用户节点表示之间的互信息。此外，KGCL [88] 将dropout应用于知识图，并提出了一种知识感知对比方法，对比从用户-物品图和知识图的增强中学习到的节点表示。

对于\textbf{全局-全局对比}（Global-Global Contrast），通常在序列推荐模型中使用，其中序列被视为用户的全局视图。作为代表性模型，CL4SRec [59] 使用三种随机增强方法——物品屏蔽、物品裁剪和物品重新排序—来获取序列的增强视图。CoSeRec[61]用相关项目替换短序列中的项目，或将相关项目插入短序列中进行鲁棒的数据增强，而ContraRec[92]不仅对比从相同输入增强的序列，还将具有相同目标项目的序列视为正样本。此外，DHCN [29]通过建模会话内和会话间的结构信息，创建给定会话的两个基于超图的视图。

对于\textbf{局部-全局对比}（Local-Global Contrast），旨在将全局信息编码到局部结构表示中，并统一全局和局部语义。它经常在图学习场景中使用。EGLN [67] 提出通过将合并的用户-物品对表示与全局表示进行对比来实现局部-全局一致性，其中全局表示是所有用户-物品对表示的平均值。类似地，BiGI [69] 执行局部-全局对比，但仅对其h-hop子图进行特征聚合以生成用户-物品对表示。在HGCL [93] 中，构建了用户和物品节点类型特定的同质图。对于每个同质图，它使用DGI [17] 过程最大化图的局部补丁与整个图的全局表示之间的互信息。它还提出了跨类型对比来衡量不同类型同质图之间的局部和全局信息。

对于\textbf{局部-上下文对比}（Local-Context Contrast），旨在将全局信息编码到局部信息的上下文表示中，并统一局部和上下文的语义。受 [79] 的启发，NCL [78] 设计了一种原型对比目标，以捕捉用户/物品与其原型之间的相关性，原型表示一组语义邻居。原型是通过使用K-means算法对所有用户或物品嵌入进行聚类获得的，并使用EM算法递归调整原型。这一思想也体现在序列推荐中[77]，其中语义原型被建模为用户意图，而所属序列是原型的局部视图。S3-Rec [26] 应用项目屏蔽和项目裁剪来增强序列，并设计了四个对比任务来预训练双向Transformer进行下一个项目的预测：项目-属性互信息最大化（MIM）、序列-项目MIM、序列-属性MIM和序列-序列MIM。



\section{对比学习相关工作}

\subsection{对比学习基础概念}
从统计学习的角度来看，机器学习模型可以分为两类：生成模型和判别模型\cite{li:2019}。给定特征$X$和标签$Y$的联合分布$P(X,Y)$，生成模型旨在建模
\[p(X|Y=y)= \frac{p(X,Y)}{p(Y=y)}\]
而判别式模型旨在建模
\[p(Y|X=x)= \frac{p(X,Y)}{p(X=x)}\]
生成式模型需要重构特征$X$的像素级信息，从而捕捉特征之间的潜在关系。而判别式则是直接对后验概率建模，旨在激励编码器编码不同类别样本之间的差异特征，不编码像素级特征。对比学习属于判别式的一种，旨在通过噪声对比估计（Noise Contrastive Estimation，NCE）\cite{Gutmann:2010:ICAIS}的目标函数在比较中学习（learn to compare）
\begin{eqnarray}
\mathcal{L}_\textsc{Nce} = \mathbb E[-\log \frac{\exp(f(x)^Tf(x^+))}{\exp(f(x)^Tf(x^+))+\exp(f(x)^Tf(x^-))}]
\end{eqnarray}
其中，$x$是锚点，在推荐中通常选择用户$u$，$x^+$是锚点的正例，在推荐中通常选择为已交互的物品$i$，于是$(u,i)$构成正例对；$x^-$为锚点的负例，在推荐中通常选择为未交互的物品$j$，于是$(u,j)$构成负例对。$f$是编码器，$f(x)^Tf(x^+)$是由编码器参数化的正例对相似度得分，通常为内积相似度或者余弦相似度，记为$\hat{x}_{ui}$。类似地，$f(x)^Tf(x^-)$是负例对似度得分，记为$\hat{x}_{uj}$。可以看到，NCE损失函数与BPR损失\cite{Steffen:2009:UAI}的联系：
\begin{eqnarray}
	\mathcal{L}_\textsc{Nce} 
	&=& \mathbb E[-\log\frac{\exp(\hat{x}_{ui})}{\exp(\hat{x}_{ui})+\exp(\hat{x}_{uj})}]\nonumber \\
	&=& \mathbb E[-\log\frac{1}{1+\exp(\hat{x}_{uj}-\hat{x}_{ui})}]\nonumber \\
	&=& \mathbb E[-\log \sigma (\hat{x}_{ui} - \hat{x}_{uj})]\nonumber \\
	&=& \mathcal{L}_\textsc{Bpr} 
\end{eqnarray}
其中$\sigma(\cdot)$为sigmoid函数。在实践中，由于要引入正则化项避免过拟合，而正则化项又等价于高斯分布先验密度的对数，从而BPR将上式解释为观测到的有序对的最大后验估计。尽管BPR和NCE有着不同的解释，且编码器$f$的网络架构在不同任务中差异很大，但是BPR与NCE有着完全相同的数学形式，共享相同的优化目标。

需要说明的是，正例对或者负例对的概念在不同场景下差异很大，例如SimCLR\cite{Chen:2020:ICML}将同一个图像的两次增强构造为正例对，BPR\cite{Steffen:2009:UAI}将用户和交互过的物品构建为正例对，LightGCL\cite{lightgcl:2023:ICLR}将增强图和原图中的同一个用户构造为正例对。具体的正例或负例语义可以根据任务以及场景进行迁移和拓展。将NCE中加入更多的负例，那么可以得到InfoNCE损失\cite{Oord:2018:arxiv}：
\begin{eqnarray}
	\mathcal{L}_\textsc{InfoNCE} = \mathbb E[-\log \frac{\exp(f(u)^Tf(i))}{\exp(f(u)^Tf(i))+\sum_{n=1}^{N}\exp(f(u)^Tf(j_n))}]
\end{eqnarray}

可以看到，NCE和BPR是InfoNCE负例个数$N=1$的特例。以最具一般性的InfoNCE损失为例，它的含义是正确分类正样本的交叉熵\cite{Oord:2018:arxiv}，最小的InfoNCE损失为0，在正例相似度得分与负例相似度得分满足$\exp(f(x)^Tf(x^-_j)- f(x)^Tf(x^+))\rightarrow -\infty, j \in \{1,2,\cdots N\}$时取到。这一结论也适用于NCE和BPR，只是负例个数$N=1$。

进一步地，相似度分数与欧氏距离是一一对应的负相关关系。对于投影到单位超球面的两个$d$维向量$\mathbf{x} = (x_1,x_2,\cdots,x_d)$和$\mathbf{y} = (y_1,y_2,\cdots,y_d)$欧式距离$d(\mathbf{x},\mathbf{y})$与内积相似度分数$\mathbf{x}^T\mathbf{y}$存在如下关系：
\begin{eqnarray}
d(\mathbf{x},\mathbf{y}) &=& \sqrt{(x_1-y_1)^2+\cdots +(x_d-y_d)^2} \nonumber \\
&=&\sqrt{2-2\mathbf{x}^T\mathbf{y}} \nonumber
\end{eqnarray}
因此相似度分数越高，距离越近。

基于上述分析，可以从三个方面归纳对比学习的特征：
\begin{itemize}
\item 从数值角度看，对比学习优化正例得分大于负例得分，只优化相似度分数的差值，不优化具体值，以激励学习数据的内在结构和特性。
\item 从嵌入空间中看，对比损失激励编码器拉近正例与锚点的距离，推远负例与锚点的距离，实现编码不同样本的差异特征，而非样本本身的像素级信息。文献\cite{Wang:2022:KDD}和文献\cite{Wang:2020:ICML}分别阐释了优化BPR损失以及InfoNCE损失都是在优化正样本对齐、负样本的均匀。
\item 从统计角度看，对比学习优化“正确分类正样本的概率”\cite{Oord:2018:arxiv}，体现判别式方法的特征，即直接对样本所属类别的后验概率建模。
\end{itemize}

%\section{对比学习相关工作}
%对比学习有几个关键组件：（1）负例，（2）正例，（3）网络架构，（4）对比损失函数，共同决定了对比学习的效果。本节根据对比学习的组件，分别从负例采样方法、正例增强方法、网络架构设计和损失函数设计四个方面总结对比学习的相关工作。
\subsection{负样本采样方法相关工作}
%*******************************
\begin{figure*}[!]
	\centering
	\includegraphics[width=0.9\textwidth]{fhn.pdf}
	\caption{困难负例和伪负例示意图}
	\label{2Fig:illustrative}
\end{figure*}
%*******************************
对比学习有两个关键属性：正样本特征的对齐和负样本的均匀\cite{Wang:2020:ICML}。如果仅仅优化正样本之间的距离，会使得任意样本之间的距离接近于零，即为所有的样本输出相同的表示，从而使得神经网络学到坍缩的解。由于大多数情况下缺乏明确的负信号，尤其是推荐系统中用户只对感兴趣的物品提供交互，因此负采样策略被广泛研究。以图\ref{2Fig:illustrative}的一个直观的示例解释负采样策略的两个关键目标：锚点为狗，负例候选样本$x_1^\prime$是狼，与锚点不同类，但是特征很相似，也称为困难负样本(hard negative sample)。负例候选样本$x_3^\prime$是狗，与锚点同类，但是由于缺乏监督标签也出现在负例候选集，称为伪负样本(false negative sample)。为了使得同类样本的表示距离较近，那么$x_1^\prime$狼这个困难负例应该被选作负样本，使其被推远，防止其混入狗这个类别；且$x_3^\prime$狗这个伪负例不应该被选作负样本，防止其被推远。推荐领域的任务也是一样，只是正负样本语义是用户喜欢与否。负采样（NS）的策略是从候选的未标注样本中采样负样本，核心目标围绕如何采样困难负样本且剔除伪负样本展开。许多研究表明，负采样对于提高下游的分类或推荐性能非常重要~\cite{Steffen:2014:WSDM,Zhang:2013:SIGIR,Ding:2020:NIPS,Park:2019:WWW,Huang:2021:KDD,Ding:2019:IJCAI,Yang:2020:KDD}。

\subsubsection{采样困难负样本}
采样困难负样本的主要目标是采样类似于样本$x_1^\prime$这样的困难负样本。它们与正例很相似，但是所属类别为负类。由于这两个样本在特征上相似度很高, 难以区分，在经过网络提取特征之后, 它们特征之间的相似度分数也比较高。采样此类样本一方面会使得不同类别的困难负样本被推远，迫使神经网络学习难以区分的样本之间的边界；另一方面，这类样本分数较高，梯度值较大，从而神经网络的参数更新更多，提高训练效率。基于上述动机，很多困难负采样(hard negative sampling)方法被提出，它们采用自适应采样分布的“困难负采样”，以针对困难负例进行采样~\cite{Steffen:2014:WSDM,Zhang:2013:SIGIR,Ding:2020:NIPS,Park:2019:WWW,Huang:2021:KDD,Ding:2019:IJCAI}。

在推荐领域，最具代表性的困难负采样方法为动态负采样\cite{Zhang:2013:SIGIR}。由于困难负样本的表示与正例比较接近，因此困难负样本对应的相似度分数也比较高。动态负采样通过在若干个候选的负例中采样相似度分数比较高的样本，从而实现每个样本的采样概率分布正比于其相对排序位置。类似地，Steffen等人\cite{Steffen:2014:WSDM}提出排名位置靠前的负例进行过采样。他们的思想是类似的，因为排序位置与相似度分数是一一对应的。除了使用分数相似度或者相对排序位置来表征负例的困难等级(hardness level)，还有研究者使用图的相关信息来采样困难负样本。例如，Wang等人~\cite{Wang:2020:WWW}和Wang等人~\cite{Wang:2021:CIKM}提出利用知识图谱上的关系类型来采样困难负例。另一种方使用较多的是选择与正例在图结构上相似的困难负例~\cite{Chen:2019:WWW,Wang:2021:TKDE,Ying:2018:KDD}。文献\cite{shi2023theories}分析了，困难负采样实际上是在优化推荐列表指定伪正例例率（FPR）范围内的AUC面积（ one-way partial AUC），但没有考虑困难负采样带来的伪负例问题。

\subsubsection{剔除伪负样本}
剔除伪负样本的主要目标是避免采样类似于样本$x_3^\prime$这样的伪负样本。由于缺乏标签，它们虽然出现在负例候选集，但是所属类别为正类。在推荐领域，这类样本对应于用户没有看到过，但是潜在喜欢的物品。由于这个样本所属类别为正类，因此应当避免采样到此类样本，防止其在嵌入空间被推远。另一方面，采样此类物品，会使得模型误判用户的兴趣边界。因此，负采样的另外一个重要目标就是防止采样到伪负例。最普遍方法是使用附加信息来避免采样伪负例。这些附加信息对于提取负信号非常直观，例如社交网络中用户的连接关系~\cite{Zhao:2014:CIKM,Wang:2016:CIKM}、用户的地理位置~\cite{Yuan:2016:IJCAI,Liu:2019:IJCAI}，以及额外的交互数据，如已查看但未点击的数据~\cite{Jingtao:2019:IJCAI, Jingtao:2018:WWW}，但是这些额外信息通常不好获得，只有特定的数据集才有。

为了避免采样伪负例，还有一类新的方法是使用多个负例中生成虚拟的负样本用于模型训练。例如，Huang等人~\cite{Huang:2021:KDD}提出通过混合候选负样本的嵌入来合成虚拟的困难负例。Jun等人~\cite{Jun:2017:SIGIR}和Park等人~\cite{Park:2019:WWW}设计了生成对抗神经网络来生成虚拟的困难负例。合成虚拟负样本的方法也广泛使用在计算机视觉中，例如Zhu等人\cite{zhu:2021:iccv}提出了在特征空间上将负样本对应的嵌入插值，类似于构造了虚拟的负样本，而对正样本的嵌入外推，最终提高了对比学习的效果。 Zhong 等\cite{zhong:2021:cvpr}提出了一种结合图像混合 (Mixup) 技术的困难样本构造方法, 首先使用Mixup合成虚拟的负样本，然后依据合成负样本的相似度分数选择困难的合成负样本进行对比学习训练。

总体来说，负采样方法取得较大进展，特别是困难负采样方法对于下游任务性能提升效果非常显著。采样困难样本是容易实现的，只需要采样相似度分数高或者距离近的样本。但是如何从困难样本中采样困难负样本，还是严重依赖额外信息作为监督信号。尽管合成虚拟负样本的方法看似避免了采样伪负例，但是它的实质是将对比损失函数进行修改：虚拟样本嵌入是若干个负例的混合，那么虚拟样本的相似度分数是这几个负例相似度分数的函数，更多的样本用于合成虚拟样本，导致更多的样本包含在对比损失的分母中，并没有解决伪负样本问题。
\subsection{正样本数据增强相关工作}
数据增强的目标是获取语义不变的可靠正样本用于对比。数据增强是获取语义不变的可靠正样本的主要途径，也是提升自监督对比学习效果最重要的手段，是对比学习的重要组成部分。在传统的图像中，通常的做法是通过在锚点$x$上进行某些语义不变的数据增强来获得正样本$x^+$，如随机裁剪和翻转\cite{Oord:2018:arxiv}，图像旋转\cite{Komodakis:2018:ICLR}，和颜色失真\cite{Szegedy:2015:CVPR}等。然而，仅采用单一的图像增强方法并不利于性能提升，SimCLR\cite{Chen:2020:ICML}方法综合比较了一系列图像变换方法的效果，并发现将随机裁剪和颜色失真组合起来的变换方式能够获得更好的效果。

受到图像领域的启发，在推荐领域的正样本数据增强工作也得到了广泛的研究。在推荐中数据增强的核心思想是在原有图结构的基础上略作扰动，并以此增强后的新图产生一组新的表征向量，然后将这组新的表征向量与原图产生的表征向量进行对齐，并将不属于同一结点的表征向量互相推远。然而，推荐系统数据集通常以用户物品二分图的形式存在，节点只包含ID，往往使用基于图的策略进行增强。图数据的增强策略可以分为以下几种（1）基于特征的增强\cite{liu2022local,velivckovic2018deep,zhu2020deep,you2020graph,pmlr-v139-you21a}：仅对节点或者边的特征矩阵进行变换。通常随机屏蔽节点或边属性的一小部分，并用常数或随机值替换。（2）基于结构的增强\cite{pmlr-v119-zheng20d,10.1145/3437963.3441734,10.1145/3437963.3441720,page1998pagerank}：仅对邻接矩阵进行变换。通常随机（或手动）在图中添加或删除一小部分边，包括边扰动\cite{pmlr-v119-zheng20d,10.1145/3437963.3441734}、节点插入\cite{10.1145/3437963.3441720}和边扩散\cite{page1998pagerank}、图采样\cite{pmlr-v119-zheng20d}等方法。（3）基于标签的增强\cite{Steffen:2014:WSDM,zhang2020graph,verma2019manifold}：由于图上人工标注标签的不足，标签增强是图数据增强研究中的另一个重要方向，用于增加有限的标记训练数据。它可以分为两类：一类是伪标签的增强，例如BPR\cite{Steffen:2014:WSDM}将未标记样本标记为负例，即是对潜在的用户物品二分图进行了标签增强。第二类是数据混合\cite{zhang2020graph,verma2019manifold}，直接插值构建虚拟的训练样本。VGCL\cite{yang2023generative}综合考虑了特征增强和结构增强的缺陷，利用变分图重构来估计每个节点的高斯分布，然后从估计分布中进行多个采样来,生成多个对比视图。LightGCL\cite{lightgcl:2023:ICLR}则将归一化的邻接矩阵进行奇异值分解，通过抛弃被认为是噪声的较小奇异值，获得了增强视角的图用于对比。

由于图数据具有固有的非欧几里得特性，很难将图像中的随机剪裁、反转、颜色失真等保持语义不变的数据增强方法应用于图数据。基于随机过程的图数据增强可能会损失图中重要的结构信息，因为随机丢弃的点或者边可能会体现图的重要结构信息。此外，数据噪声和数据稀缺问题仍然是获取图数据增强面临的问题。
%
%\subsection{网络架构设计的相关工作}
%既然数据增强对于提升自监督对比学习的效果至关重要，那如设计更有效的网络架构，从而享受更密集的数据增强带来的好处？此外，负例的未标注是自监督对比学习与有监督对比学习的主要差异。既然有限的监督信号下难以避免采样伪负例。那么是否可以不用负样本，同时避免神经网络学到坍缩解？基上述两个主要动机，不同的网络架构被提出。由于相似度分数$\exp(f(x_1)^T,f(x_2))$计算涉及两次对样本的编码，下文把编码第一个样本的网络称为网络分支1，把编码第二个样本的网络称为网络分支2。根据两个网络分支的架构是否相同，可以分为同构网络和异构网络：前者网络分支架构相同，后者网络分支架构不同；根据两个网络分支参数的更新方式是否相同，可以分为同步网络和异步网络：前者通常采用端到端的反向传播方式更新网络参数，后者的网络分支更新方式不同，往往分别使用梯度法和动量法分别跟新两个网络分支参数。
%\subsubsection{同步同构网络架构}
%典型的同步同构网络如图\ref{2Fig:arc1}所示，代表性工作是SimCLR\cite{Chen:2020:ICML}。它采取了最自然的端到端地反向传播的方式更新神经网络参数，且两个网络分支的架构完全相同。给定一个样本，经过两次增广获得正样本对，从而受益于更密集的数据增强；然后, 通过同一个神经网络模型将样本投影到嵌入空间。这里，同一个神经网络模型即可以看作两个同构的网络分支。 对同一个Mini Batch的$N$个数据进行同样操作后，得到$2N$个表示向量；然后, 根据这$2N$个表示向量经过多层感知机(MLP)非线性映射得到投影；最后，根据投影计算InfoNCE损失，然后反向传播更新梯度。由于它使用一个神经网络模型，可以看作两个完全相同的网络分支，因此是同构网络；此外，两个网络分支是端到端地进行反向传播更新参数，因此是同步网络。
%%*******************************
%\begin{figure*}[h!]
%	\centering
%	\includegraphics[width=0.8\textwidth]{arc1.png}
%	\caption{同步同构网络架构示意图}
%	\label{2Fig:arc1}
%\end{figure*}
%%*******************************
%
%在推荐中的网络架构大都可以归纳为同步同构网络架构，但工作机制略有不同。以最常用的LightGCN\cite{Xiangnan:2020:SIGIR}为代表，第一个网络分支编码用户表示，第二个网络分支编码物品表示，即双塔结构。聚合后的用户物品表示无需投影，直接计算损失，然后反向传播更新用户和物品表示。由于用户物品表示都是采用梯度更新的方式，因此是同步更新方式；此外用于聚合用户和物品的图卷积神经网络结构相同，因此是同构网络。另一种具有代表性的是LightGCL\cite{lightgcl:2023:ICLR}：第一个网络分支编码原图的用户表示，第二个网络分支依旧编码增强图的用户表示。LightGCN优化用户和喜欢的物品表示尽量相似，和不喜欢的物品表示尽量不相似；LightGCL则优化不同视图下同一个用户的表示尽量相同，与其他用户表示尽量不同，物品表示同理。这种差异主要是源自于对正负样本的定义和语义不同：LightGCN中用户和喜欢的物品构成正样本对，LightGCL中不同视图下的同一用户构成正样本对，同一物品也构成正样本对。这是正例对(或者负例对)的定义和语义不同，不影响网络架构的组织形式以及参数更新方式。
%\subsubsection{同步异构网络架构}
%%*******************************
%\begin{figure*}[h!]
%	\centering
%	\includegraphics[width=0.8\textwidth]{arc2.png}
%	\caption{同步异构网络架构示意图}
%	\label{2Fig:arc2}
%\end{figure*}
%%*******************************
%典型的同步异构网络如图\ref{2Fig:arc2}所示：两个网络分支的参数更新方式是相同的，都采用梯度下降更新参数；但网络分支的架构不同，两个网络分支采用不同的网络结构。网络结构的不同主要有三种：（1）分支1包含投影头，分支2不包含投影头\cite{Oord:2018:arxiv}。（2）分支1和分支2都含有投影头，但投影头的结构不相同\cite{misra:2020:CVPR}。（3）用于特征提的分支1和分支2的网络结构不相同\cite{chaitanya:2020:NIPS}。以第一种为例，介绍同步异构网络架构的工作机制，典型的工作是对比预测编码(contrastive predictive coding, CPC)。在该方法中，分支1接收某个时间点的数据作为输入，分支2接收未来某个时间点的数据作为输入，目标是利用分支1的输出来预测分支2的输出，以最大化已知数据和待预测数据的互信息。在计算损失后，两个网络分支均按梯度法更新参数。
%\subsubsection{异步同构网络架构}
%%*******************************
%\begin{figure*}[h!]
%	\centering
%	\includegraphics[width=0.8\textwidth]{arc3.png}
%	\caption{异步同构网络架构示意图}
%	\label{2Fig:arc3}
%\end{figure*}
%%*******************************
%典型的异步同构网络架构如图\ref{2Fig:arc3}所示：两个网络分支架构相同，但参数更新方式不同：网络分支1采用梯度下降更新参数，而网络分支二采用动量法更新参数。使用这种异步同构的网络架构典型工作是MoCo\cite{He:2020:CVPR}。网络分支1和网络分支2架构完全相同，初始化参数也相同。第一个网络分支按照正常操作获得样本投影的特征，但是第二个网络分支把投影的特征压入队列，直到队列达到指定长度以后，对最先入队的样本特征执行出队操作，从而获得一个较大的负样本数量。最后，根据正样本的投影特征计算损失。回传梯度时，只有第一个网络分支执行反向传播更新参数，第二个网络分支的参数根据第一个网络学到的参数进行动量更新。记第一个网络分支的参数为$\theta$，第二个网络分支的参数为$\xi$，那么它们的更新方式可以写为：
%\begin{eqnarray}
%	\theta &\leftarrow& \text{optimizer}(\theta,\nabla_\theta \mathcal{L}) \nonumber\\
%	\xi &\leftarrow& \tau \xi + (1-\tau)\theta \nonumber
%\end{eqnarray}
%其中第一个网络分支的参数$\theta$通过梯度法更新以后，将学到的最新的参数$\theta$，取$(1-\tau)\theta$用于更新第二个网络分支的参数。可以看到，只有第一个网络分支参数更新以后，才能更新第二个网络分支，因此称这种参数更新方式为异步法。当衰减系数$\tau$比较大时，第二个网络分支的参数更新幅度很小。异步法区别于端到端地使用梯度下降法更新两个网络分支，它们的更新是同步的。
%
%MoCo的第一个核心操作是对网络分支2编码得到的特征执行入队操作，解耦了负样本数量与批量大小，负样本数量不再受限于GPU显存大小，从而可以为对比学习设定一个较大的负样本数量。而较大的负样本数量会推高已知数据和待预测数据互信息的下界，从而取得更好的性能。此外，较大的负样本数量也会使得正例的梯度值增加，使得神经网络模型从正样本的数据增强中学到更多信息。MoCo的第二个核心操作是，网络分支2根据网络分支1学到的最新参数，使用动量法跟新参数而非使用梯度法更新参数，一方面可以避免伪负例产生的错误梯度的影响，另一方面避免神经网络学到坍缩的解。
%
%\subsubsection{异步异构网络架构}
%
%典型的异步异构网络架构如图\ref{2Fig:arc4}所示：两个网络分支架构不同，参数更新方式也不同，代表性工作是BYOL\cite{BYOL:2020:NIPS}。在参数更新方式上，网络分支1（在线网络）采用梯度下降更新参数，而网络分支2（目标网络）采用动量法更新参数。在网络结构设计上，两个网络分支采用MoCo作为主干网络，但投影头的数量不一致，网络分支1增加了一个预测头，以提高灵活性。在损失计算上，与先前的工作截然不同：之前的工作都涉及到同一批次内的其它样本作为负样本以计算对比损失，但是BYOL的计算只涉及一个样本的两个增强视角的特征投影，只约束正例对提取到的特征尽量相似。相当于完全抛弃了负例，只优化正例的对齐，不优化负例均匀，同时实现避免了神经网络学到了坍缩解。
%%*******************************
%\begin{figure*}[h!]
%	\centering
%	\includegraphics[width=0.8\textwidth]{arc4.png}
%	\caption{异步异构网络架构示意图}
%	\label{2Fig:arc4}
%\end{figure*}
%%*******************************
%
%BYOL的第一个核心操作是和MOCO一样，在线网络分支使用梯度法更新参数，第目标网络分支采用动量法更新参数。动量法更新也称指数滑动平均法（exponential moving average，EMA），尤其是在其衰减系数$\tau$比较大时，目标网络的参数更新很慢。第二个核心操作是给在线网络加了一个经过归一化的预测头，且其参数不会更新给目标网络，相当于在线网络提取的特征和目标网络提取的特征存在缓冲地带。这两个操作都有助于分散特征，避免神经网络学到坍缩解。第三个核心操作是损失的计算，完全不涉及负样本，只涉及正样本对的特征。具体的，是经过L2归一化的两个正样本对特征向量的均方误差，相当于只约束正样本对特征的方向。由于BOYL只优化正例对的均匀，不优化负例的均匀，从而避免了伪负样本的错误梯度问题。

\subsection{损失函数设计的相关工作}
损失函数是实现对比学习“拉近同类正样本、推远不同类负样本”的关键，是对比学习的核心组件。对比损失的核心思想是通过优化变量互信息，激励编码器编码不同类别样本之间的差异信息，而非样本的像素级信息。鉴于直接最大化互信息很困难，InfoNCE\cite{Oord:2018:arxiv}率先提出将最大化互信息转化为预测真实分布与合成分布概率密度比的问题，从而实现间接优化互信息。尽管BPR\cite{Steffen:2009:UAI}、NCE\cite{Gutmann:2010:ICAIS}是InfoNCE损失负例个数为1的特例，且工作远早于InfoNCE，但是优化互信息的概念由InfoNCE率先提出。InfoNCE也广泛应用于推荐领域，文献\cite{Jiancan:2022:arxiv}证明了优化InfoNCE损失等价于优化NCDG指标。本节以更具一般性的InfoNCE损失为主线，梳理损失函数设计的相关工作。这些针对InfoNCE的改进可以很容易类比到负例个数为1的BPR损失。
\subsubsection{面向正负样本概念拓展的损失函数改进}
为了获取更密集的数据增强，SimCLR\cite{Chen:2020:ICML}将同一个样本增强两次，那么同一个批次内的N个样本经过两次数据增强就得到了2N个样本。同一个样本的两次增强$z_i,z_j$互为正例对，构造了如下对比损失
\[
\mathcal{L} = -\log \frac{\exp(f(z_i)^Tf(z_j))}{\sum_{k=1}^{2N}\mathbb I (k \neq i)\exp(f(z_i)^Tf(z_k))}
\]
其中分子是同一个样本的两个增强视图的相似度，分母是同一个样本的两个增强视图的相似度加上与其它图像两个增强视图的相似度，合计2N-1项。可以看到与InfoNCE的数学形式是一致的，只是拓宽了正负样本对的概念。MOCO\cite{He:2020:CVPR}变化在于负样本是一个提取的特征组成的队列，损失的计算方式与InfoNCE相同。类似地，在推荐中通过一些假设将正负样本对的概念进行拓展，构造了更具细粒度的正负样本对，优化BPR损失。例如被购买的物品比只浏览的物品更受用户喜欢\cite{Qiu:2018:IS}，多次交互的项目比只有一次交互的项目更受喜欢\cite{Lerche:2014:RS}；用户未看到的潜在项目应该比曝光给用户但没有交互的物品更受喜欢\cite{Wenhui:2019:WWW,Yu:2018:CIKM,Bin:2020:IS}。此外，LightGCL\cite{lightgcl:2023:ICLR}将不同视图下的相同用户视为正样本对，不同用户视为负样本对，优化InfoNCE损失。HPM\cite{huang2023dual}进一步地通过物品属性信息(如项目类别)构造正样本对。在损失函数分析中，通常不区分由于正负样本对的概念拓展造成的损失函数与初始对比损失函数的差异。

\subsubsection{面向模型坍塌问题的损失函数改进}
由于对比损失优化正例对齐，神经网络的参数空间存在一种可能的解，它为所任意样本映射为同一个相同的特征表示，这样的解也称坍缩解或者模型坍塌。尽管负例参与学习训练有助于分散特征(scatter feature)，避免模型坍塌，但也不能完全避免这种情况。基于这种情况DirectCLR\cite{jing2021understanding}取特征向量的前d维的子向量，计算对比损失
\[
\mathcal{L} = -\log \frac{\exp(f(z_i^\prime)^Tf(z_j^\prime))}{\sum_{k=1}^{2N}\mathbb I (k \neq i)\exp(f(z_i^\prime)^Tf(z_k^\prime))}
\]
其中，$z^\prime = z[0:d]$是原始特征向量的前d个维度构成子向量，这个对比损失与SimCLR损失的唯一区别就是只取每个特征向量的前d维。

BYOL\cite{BYOL:2020:NIPS}进一步改进了对比损失。对同一个样本的两次增强，两个网络分支学到的归一化特征表示分别记为$\bar q(z)$和$\bar z\prime $，BYOL优化归一化特征表示的均方误差：
\[||\bar q(z)-\bar z\prime||^2 =2-2\cdot \frac{\langle q(z),z\prime \rangle}{||q(z)||_2\cdot||z\prime||_2  } = 2-2\cos(q(z),z\prime)\]
其中为$q(z),z\prime$分别为两个网络分支学到的特征表示向量（未归一化）。可以看到，BYOL实际上只约束两个网络分支学到的特征表示的方向一致，并不规定正例对表示向量的具体模值。除了损失函数外，BYOL还通过精致的网络架构设计和正则化技术分散特征，避免神经网络学到坍缩解。

\subsubsection{面向梯度消失问题的损失函数改进}
InfoNCE损失函数的形式决定了其正例梯度等于所有负例梯度的和，符号相反。对于一个分数较小的负样本(容易负样本)，或者分数较大的正样本(容易正样本)，梯度容易消失，使得模型从样本中学到较少的信息。具体到负例个数为1的BPR损失中，就有正例的梯度等于负例的梯度，同样符号相反，使得梯度消失的问题更加明显，因此往往需要通过保持较大的负例个数N，以避免梯度消失的问题。于是解耦对比损失\cite{yeh:2022:ECCV}（Decoupled Contrastive Learning）去掉了InfoNCE失函数分母中两个正样本对之间的相似度，损失函数的形式计算如下：
\[
\mathcal{L} = -\log \frac{\exp(f(x)^Tf(x^+))}{\sum_{i=1}^{N}\exp(f(x)^Tf(x^-))}
\]
解耦对比损失在一定程度上解决了容易正样本和容易负样本所导致的梯度消失问题，也避免了负样本数量对梯度的放缩。


\subsubsection{面向自监督场景的损失函数改进}
在自监督场景下伪负例的存在，使得InfoNCE损失实际上优化实例之间的对齐和均匀，而非不同类别样本的均匀与对齐。更具体地，由于伪负例包含其中，在自监督场景下，InfoNCE实际上是拉近同一个样本的增强之间的距离，推远不同的样本而非不同类别的样本之间的距离，因为任意锚点以外的样本都被视作负样本。负例的无监督，使得自监督场景下InfoNCE偏离了原始的优化目标，对下游分泛化性能产生了不利的影响。为了鼓励编码器去编码数据的语义结构，拉近同类样本，推远不同类样本，ProtoNCE\cite{Li:2021:ICLR}通过改进正负样本对的语义，以改进对比损失。具体地，当前样本的特征与其对应的聚类中心构成正样本对，而与其他聚类中心形成负样本对，从而得到如下优化目标：
\[
\mathcal{L} = -\log \frac{\exp(f(x)^Tf(c_i))}{\sum_{i=1}^{C}\exp(f(x)^Tf(c_i))}
\]
其中$c_i$为聚类中心，也被称为原型(prototypes)，通过在EM算法的期望步骤中执行k-means聚类得到。通过将分子修改为样本与所属类别中心的相似度，分母部分更改为样本与其他聚类中心之间的相似度，实现将优化目标改进为拉近样本与所属类别中心的距离，推远样本与其它类别中心的距离。这一思想在个性化推荐中也有应用\cite{lin2022improving}。

上述方案需要迭代计算，开销较大。另外一个解决负例无监督的途径是通过校正负样本相似度分数，以获取一个与有监督对比损失一致的改进损失函数，从而取得类似于监督学习的泛化效果，代表工作是去偏对比学习\cite{Chuang:2020:NIPS}（Debiased Contrastive Learning, DCL）。其核心思想是，由于伪负例包含在InfoNCE的分母中，导致的结果是分母中的负例相似度分数计算不准确。可以通过修正负例的相似度分数，实现对有监督对比损失的近似。其损失函数计算如下
\[
\mathcal{L} = -\log \frac{\exp(f(x)^Tf(x^+))}{\exp(f(x)^Tf(x^+) + N\cdot g}
\]
其中$g$是对真负样本与锚点相似度分数期望值的估计，其具体形式在后面的章节中会有更详尽的介绍。

在DCL\cite{Chuang:2020:NIPS}伪负例去偏的基础上，HCL\cite{Robinson:2021:ICLR}进一步地考虑了硬负例挖掘，即将困难负样本推远离锚点。它遵循DCL的框架，并通过如下方式进一步地加权未标注样本的相似度分数：
\[\omega_i^\textsc{Hcl} = \frac{\hat{x}_j^\beta}{\frac{1}{N} \sum_{j=1}^{N}\hat{x}_j^\beta}
\]
其中$\hat{x}$是未标注样本与锚点的相似度分数，$\beta$是超参数。因此，未标注样本的相似度分数越高，其分配到的权重就越大，导致其被推的越远。基于估计校正的损失函数改进，避免了额外的计算开销，取得了很好的效果。

\section{预备知识}
对于深度神经网络而言，准确推导其输出的相似度分数的分布是很困难的，本文会频繁使用来自样本计算得到的经验分布函数来近似。此外，个性化推荐是一个排序任务，次序统计量作为排序分析的一个有力工具，本文也会频繁使用到。最后，成对学习是极大似然估计量，也会频繁使用到。因此本节对这三个会频繁用到的预备知识进行介绍。


\subsection{经验分布函数}
在介绍经验分布函数之前，先回顾累积分布函数(cumulative distribution function, CDF)的定义。对于一个实值随机变量$X$，累积分布函数（CDF）在x处的值表示随机变量X取值小于或等于x的概率
\[F(x) = \mathbb P (X\leq x)\]
$F(x)$满足${\displaystyle \lim _{x\rightarrow -\infty }F(x)=0}$且${\displaystyle \lim _{x\rightarrow \infty }F(x)=1}$。

对于连续随机变量$X$，其累积分布函数CDF可以表示为其概率密度函数$f_X$的积分，如下所示：
\[{\displaystyle F(x)=\int _{-\infty }^{x}f_{X}(t)\,dt}\]
因此，只要给出概率密度函数$f_X(x)$的表达式，就可以准确计算累积分布函数$F(x)$。然而在绝大部分场景下，获取概率密度函数$f_X(x)$的表达式是困难的，那么累积分布函数$F(x)$的计算通常依赖于经验分布函数。

经验分布函数，通常也称为经验累积分布函数（empirical cumulative distribution function, eCDF）是与样本的经验观测相关联的分布函数。在观测变量的任何指定值处，经验分布函数定义为小于或等于指定值的观测变量的比例：
\begin{eqnarray}
\hat F(x) = \frac{1}{N}\sum_{i=1}^{N} \mathbb I (X_i\leq x)
\end{eqnarray}
其中，$\mathbb I(\cdot)$是指示函数。以一个例子说明经验分布函数的计算。假设有五个独立同分布的观测值$\{3,7,2,6,4\}$，那么可以计算得到 $\hat F(1) = 0$，表明五个观测值小于等于1的占比为0；$\hat F(2) = 1/5$，表明五个观测值小于等于2的占比为1/5；$\hat F(3) = 2/5$，表明五个观测值小于等于3的占比为2/5。以此类推，$\hat F(100) = 1$，表明五个观测值小于等于100的占比为1。


经验分布函数$\hat F(x)$是标准的累积分布函数$ F_{X}(x)$的估计\cite{mou:2006}。对于固定的$x$，指示函数${\displaystyle \mathbb {I}({X_{i}\leq x})}$是一个参数为$p=F(x)$的伯努利随机变量。因此，${\displaystyle n{\widehat {F}}(t)}$是一个具有均值$nF(t)$和方差$nF(t)(1-F(t))$的随机变量。这意味着$\hat F(t)$是$F(t)$的无偏估计量。此外，根据Glivenko定理~\cite{glivenko:1933}证明了，经验分布函数一致收敛于分布函数。

在很多场景下，想获取累计分布函数(CDF)$F(x)$的解析表达式是非常困难的，但是计算经验分布函数(eCDF)却非常容易实现。于是可以通过计算经验分布函数(eCDF)，以实现对抽象的分布函数的近似。经验分布函数是一个强有力的工具，通过少数观测样本对难以获取的分布函数进行近似，实现对总体分布特征的刻画，本文会多次使用这个工具。

\subsection{次序统计量}
对于n个独立同分布随机变量$X_1, X_2, \cdots, X_n$，根据其取值升序排列，有
\[X_{(1)} \leq X_{(2)} \leq \cdots \leq X_{(n)} \]
那么称$X_{(k)}$为排序第$k$的次序统计量\cite{David:2004}。下面简单分析如何求解次序统计量$X_{(k)}$的概率密度表达式。

记随机变量$X$的概率密度为$f(x)$，相应的累积分布函数记为$F(x) = \int_{ - \infty }^x f(t)dt$，可以使用概率微元法\cite{mou:2006}求得次序统计量$X_{(k)}$的概率密度表达式。

对于随机变量的$n$个观测值$\{x_i\}_{i=1}^n$，一定存在一个足够小的区间$dx_k$，使得有且仅有一个随机变量$X_{(k)}$的取值$x_k \in [x_k, x_k+dx_k]$，如图\ref{Fig:order}所示。由于次序统计量$\{X_{(k)}\}_{k=1}^n$是根据它们的取值升序排列，那么前$k-1$个随机变量$\{X_{(i)}\}_{i=1}^{k-1}$的取值$\{x_i\}_{i=1}^{k-1} \in (- \infty ,{x_k})$, 剩余的 $n-k$个随机变量$\{X_{(i)}\}_{i={k+1}}^{n}$的取值$\{x_{i}\}_{i=k+1}^n \in ({x_k} + d{x_k},\infty )$。$X_{(k)}$的概率微元可以计算为
\begin{figure}[!t]
	\centering
	\includegraphics{2-order.png}
	\caption{次序统计量的概率微元}
	\label{Fig:order}
\end{figure}
\begin{equation}\label{Eq:ProbDiff}
	\begin{aligned}
		g({x_k}; k,n)d{x_k} = \frac{{n!}}{{(k - 1)!(n - k)!}}{[F({x_k})]^{k - 1}} f({x_k})d{x_k}{[1 - F({z_k})]^{n - k}} + o(d{x_k}) \nonumber
	\end{aligned}
\end{equation}
$g({x_k}; k,n)$即为次序统计量$X_{(k)}$的概率密度。其中，${[F({z_k})]^{k - 1}}$是前$k-1$个随机变量落入区间$(- \infty ,{x_k})$的概率；${[1 - F({x_k})]^{n - k}}$是后面$n-k$个变量落入区间$({x_k},\infty )$的概率，因为$1 - F({x_k}) = P(X > {x_k})$。 $o(d{x_k})$是$d{z_k}$的高阶无穷小量。将上式两边同时除以$d{z_k}$，则可以获得次序统计量的密度表达式
\begin{equation}
	\begin{aligned}
g({x_k};k,n) =   \frac{{n!}}{{(k - 1)!(n - k)!}} {[F({z_k})]^{k - 1}}f({x_k}){[1 - F({x_k})]^{n - k}} \nonumber
	\end{aligned}
\end{equation}
\begin{figure}[!htbp]
	\centering
	\includegraphics[width=0.8\textwidth]{order2.png}
	\caption{随机变量及其次序统计量分布示意图}
	\label{Fig:order2}
\end{figure}
上式意味着，只要给出随机变量的分布$f(x)$，就可以写出对应的次序统计量分布$g(x)$。图\ref{Fig:order2}给出了正态分布$N(1,5)$的随机变量对应的次序统计量分布$g({x};k=2,n=5)$的示意图。可以看到，次序统计量的分布$g(x)$比$f(x)$更窄。可以使用一个例子理解这一现象：假设学生考试成绩$X$独立同分布于$f(x)$。那么在一个班级中排名最后的学生的成绩的分布可以推导为$g(x)$，其可能的成绩分数比分布$f(x)$更窄。这是因为"排名最后的学生"这个信息减少了随机变量$X$的不确定性。

如果随机变量$X$中，只包含两个总体，例如正例总体和负例总体，那么可以取$n=2$，得到次序统计量$X_{(1)}$和次序统计量$X_{(2)}$的密度为：
\begin{eqnarray}
g(x_1) &=& 2 f(x) [1-F(x)] \\
g(x_2)&=& 2 f(x)F(x)
\end{eqnarray}

次序统计量是非参数统计推断的最基本工具，广泛应用于诸多统计理论与实践，如分位数估计、极值分析等、排序分析等。由于个性化推荐是一个排序任务，因此次序统计量也为推荐算法提供了重要的工具。上式的两个结论，会在后面的章节多次应用。

\subsection{极大似然估计}
极大似然估计（MLE）是一种估计参数化的概率分布的方法。其基本思想是，在参数空间内，求解一个模型参数$\Theta$，使得在一次实验中观测到观测值（也称为证据）$X$的概率最大。这通过最大化似然函数来实现：
\[\arg \max p(X|\Theta)\]
其中，$p(X|\Theta)$称为似然，反映了模型参数$\Theta$对观测证据$X$的解释程度\cite{mou:2006}。以BPR为例，简单介绍极大似然估计的运作原理。给定观测到的正负样本对$X$，用户“偏好正例$i$强于负例$j$”的似然被建模为
\[p(X|\Theta) = -\log \sigma (\hat{x}_{ui} - \hat{x}_{uj})\]
其中$\hat{x}_{ui},\hat{x}_{uj}$是由用户物品特征表示$\Theta$参数化的偏好预测值。那么$p(X|\Theta)$描述了当前模型参数下，观测到用户偏好物品$i$强于$j$的概率。引入样本的独立性假设后，多个样本的似然函数是多个单个样本似然的乘积。通过对数运算将乘积运算转化为求和运算，原始的极大似然估计问题往往转化为最大化对数似然问题。

在实践中，由于要引入正则化项避免过拟合，而正则化项又等价于高斯分布先验密度的对数，因此正则化项为BPR的估计量提供了后验概率解释。
将BPR解释为极大似然估计，还是最大后验估计，主要是对正则化项的语义理解不同：若狭义地理解正则化项，那么BPR的估计量即为极大似然估计量；若把正则化项理解为高斯先验密度的对数，那么BPR为最大后验估计量。在本文成对学习的具体环境中，不区分由正则化项的语义造成的极大似然或者最大后验估计的概念差异。从贝叶斯推断的角度来看，极大似然估计通常等同于具有均匀先验分布（或标准差为无穷大的正态先验分布）的最大后验估计（MAP）估计\cite{beye:book}。

%极大似然通过求解参数，使得一次观测发生的概率最大化，体现的是频率学派的观点。极大似然思想也广泛体现在日常生活中，例如“要下雨（参数）了，不然不会这么闷热（观测证据）”，根据当前闷热的观测证据推断为要下雨，体现的正是极大似然原理。





